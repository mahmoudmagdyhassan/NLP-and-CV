{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCw36mQclZ_-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from ipywidgets import IntSlider, interact\n",
        "from matplotlib import animation, rc\n",
        "from matplotlib.patches import PathPatch, Rectangle\n",
        "from matplotlib.path import Path\n",
        "import scipy\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import zoom\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import (BatchNormalization, Conv3D, Dense,\n",
        "                                     Dropout, GlobalAveragePooling3D,\n",
        "                                     MaxPool3D)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" numpy version: {np.__version__}\")\n",
        "print(f\" nib version: {nib.__version__}\")\n",
        "print(f\" cv2 version: {cv2.__version__}\")\n",
        "print(f\"tensor flow version: {tf.__version__}\")\n",
        "import matplotlib\n",
        "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
        "print(f\"scipy version: {scipy.__version__}\")"
      ],
      "metadata": {
        "id": "k4rx90A2lgiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download url of normal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-0.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "# Download url of abnormal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-23.zip\")\n",
        "keras.utils.get_file(filename, url)"
      ],
      "metadata": {
        "id": "7usctqRDlmp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"MosMedData\")"
      ],
      "metadata": {
        "id": "ay2r2p7Zly16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip data in the newly created directory.\n",
        "with zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"/content/MosMedData/\")\n",
        "with zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"/content/MosMedData/\")"
      ],
      "metadata": {
        "id": "edjVyK9Il0hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_nifti_file(filepath):\n",
        "    scan = nib.load(filepath)\n",
        "    scan = scan.get_fdata()\n",
        "    return scan\n",
        "def normalize(volume):\n",
        "    min = -1000\n",
        "    max = 400\n",
        "    volume[volume < min] = min\n",
        "    volume[volume > max] = max\n",
        "    volume = (volume - min) / (max - min)\n",
        "    volume = volume.astype(\"float32\")\n",
        "    return volume\n",
        "def resize_volume(img):\n",
        "    desired_depth = 64\n",
        "    desired_width = 128\n",
        "    desired_height = 128\n",
        "    current_depth = img.shape[-1]\n",
        "    current_width = img.shape[0]\n",
        "    current_height = img.shape[1]\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
        "    return img\n",
        "def process_scan(path):\n",
        "    volume = read_nifti_file(path)\n",
        "    volume = normalize(volume)\n",
        "    volume = resize_volume(volume)\n",
        "    return volume"
      ],
      "metadata": {
        "id": "AubEKegqmLH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder \"CT-0\" consist of CT scans having normal lung tissue,\n",
        "# no CT-signs of viral pneumonia.\n",
        "normal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-0\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-0\")\n",
        "]\n",
        "# Folder \"CT-23\" consist of CT scans having several ground-glass opacifications,\n",
        "# involvement of lung parenchyma.\n",
        "abnormal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-23\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-23\")\n",
        "]\n",
        "\n",
        "print(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\n",
        "print(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))"
      ],
      "metadata": {
        "id": "Vdb5tZSFqWP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abnormal_scans = normal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n",
        "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n",
        "\n",
        "abnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\n",
        "normal_labels = np.array([0 for _ in range(len(normal_scans))])\n",
        "\n",
        "x_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\n",
        "y_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\n",
        "x_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\n",
        "y_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\n",
        "print(\n",
        "    \"Number of samples in train and validation are %d and %d.\"\n",
        "    % (x_train.shape[0], x_val.shape[0])\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gb699ws7ssA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from scipy import ndimage\n",
        "@tf.function\n",
        "def rotate(volume):\n",
        "    def scipy_rotate(volume):\n",
        "        angles = [-20, -10, -5, 5, 10, 20]\n",
        "        angle = random.choice(angles)\n",
        "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
        "        volume[volume < 0] = 0\n",
        "        volume[volume > 1] = 1\n",
        "        return volume\n",
        "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
        "    return augmented_volume\n",
        "def train_preprocessing(volume, label):\n",
        "    volume = rotate(volume)\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label\n",
        "def validation_preprocessing(volume, label):\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label"
      ],
      "metadata": {
        "id": "65IhzYQ9thUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))"
      ],
      "metadata": {
        "id": "jJu53W5bwG25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=2\n",
        "train_dataset=(\n",
        "    train_loader.shuffle(len(x_train))\n",
        "    .map(train_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2))\n",
        "validation_dataset=(\n",
        "    validation_loader.shuffle(len(x_val))\n",
        "    .map(validation_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2))"
      ],
      "metadata": {
        "id": "XGNzj4KTwJFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = train_dataset.take(1)\n",
        "images, labels = list(data)[0]\n",
        "images = images.numpy()\n",
        "image = images[0]\n",
        "print(\"Dimension of the CT scan is:\", image.shape)\n",
        "plt.imshow(np.squeeze(image[:, :, 50]), cmap=\"gray\")"
      ],
      "metadata": {
        "id": "FM0Noxu00LzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_slices(num_rows, num_columns, width, height, data):\n",
        "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
        "    data = np.rot90(np.array(data))\n",
        "    data = np.transpose(data)\n",
        "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
        "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
        "    heights = [slc[0].shape[0] for slc in data]\n",
        "    widths = [slc.shape[1] for slc in data[0]]\n",
        "    fig_width = 12.0\n",
        "    fig_height = fig_width * sum(heights) / sum(widths)\n",
        "    f, axarr = plt.subplots(\n",
        "        rows_data,\n",
        "        columns_data,\n",
        "        figsize=(fig_width, fig_height),\n",
        "        gridspec_kw={\"height_ratios\": heights},\n",
        "    )\n",
        "    for i in range(rows_data):\n",
        "        for j in range(columns_data):\n",
        "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
        "            axarr[i, j].axis(\"off\")\n",
        "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Visualize montage of slices.\n",
        "# 4 rows and 10 columns for 100 slices of the CT scan.\n",
        "plot_slices(4, 10, 128, 128, image[:, :, :40])"
      ],
      "metadata": {
        "id": "FVx66y2B2KJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(width=128, height=128, depth=64):\n",
        "\n",
        "    inputs = keras.Input((width, height, depth, 1))\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "    x = layers.GlobalAveragePooling3D()(x)\n",
        "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_model(width=128, height=128, depth=64)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "SdNby8yx1LMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_learning_rate = 0.001\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),metrics=[\"acc\"],)\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"3d_image_classification.h5\", save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
        "epochs = 100\n",
        "model.fit(train_dataset,validation_data=validation_dataset,epochs=epochs,shuffle=True,verbose=2,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],)"
      ],
      "metadata": {
        "id": "K8uJELbj5Zcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/my_trained_model (1).h5')\n",
        "input_volume = x_val[0]\n",
        "prediction = model.predict(np.expand_dims(input_volume, axis=0))[0]\n",
        "scores = [1 - prediction[0], prediction[0]]\n",
        "class_names = ['normal', 'abnormal']\n",
        "for score, name in zip(scores, class_names):\n",
        "    print(f'This model is {(100 * score):.2f} percent confident that CT scan is {name}.')\n"
      ],
      "metadata": {
        "id": "62V8rHbsIsLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy import ndimage\n",
        "\n",
        "# Define the functions for reading, normalizing, resizing, and processing the scan\n",
        "def read_nifti_file(filepath):\n",
        "    \"\"\"Read and load volume\"\"\"\n",
        "    # Read file\n",
        "    scan = nib.load(filepath)\n",
        "    # Get raw data\n",
        "    scan = scan.get_fdata()\n",
        "    return scan\n",
        "\n",
        "def normalize(volume):\n",
        "    \"\"\"Normalize the volume\"\"\"\n",
        "    min_value = -1000\n",
        "    max_value = 400\n",
        "    volume[volume < min_value] = min_value\n",
        "    volume[volume > max_value] = max_value\n",
        "    volume = (volume - min_value) / (max_value - min_value)\n",
        "    volume = volume.astype(\"float32\")\n",
        "    return volume\n",
        "\n",
        "def resize_volume(img):\n",
        "    desired_depth = 64\n",
        "    desired_width = 128\n",
        "    desired_height = 128\n",
        "    current_depth = img.shape[-1]\n",
        "    current_width = img.shape[0]\n",
        "    current_height = img.shape[1]\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
        "\n",
        "    if img.shape[-1] < desired_depth:\n",
        "        pad_depth = desired_depth - img.shape[-1]\n",
        "        img = np.pad(img, ((0, 0), (0, 0), (0, pad_depth), (0, 0)), mode='constant')\n",
        "    elif img.shape[-1] > desired_depth:\n",
        "        crop_depth = img.shape[-1] - desired_depth\n",
        "        img = img[:, :, :, :img.shape[-1] - crop_depth]\n",
        "\n",
        "    return img\n",
        "\n",
        "def process_scan(path):\n",
        "    volume = read_nifti_file(path)\n",
        "    volume = normalize(volume)\n",
        "    volume = resize_volume(volume)\n",
        "\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "\n",
        "    return volume\n",
        "\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model('/content/my_trained_model (1).h5')\n",
        "\n",
        "file_path = \"/content/MosMedData/CT-23/study_0941.nii.gz\"\n",
        "\n",
        "processed_volume = process_scan(file_path)\n",
        "volume_size = processed_volume.shape\n",
        "print(\"volume_size\",volume_size)\n",
        "\n",
        "\n",
        "prediction=model.predict(np.expand_dims(processed_volume, axis=0))[0]\n",
        "\n",
        "# Calculate scores\n",
        "scores = [1 - prediction[0], prediction[0]]\n",
        "\n",
        "# Class names\n",
        "class_names = ['normal', 'abnormal']\n",
        "\n",
        "# Display the predictions\n",
        "for score, name in zip(scores, class_names):\n",
        "    print(f'This model is {(100 * score):.2f} percent confident that CT scan is {name}.')\n"
      ],
      "metadata": {
        "id": "AIKMDF6pI8ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "last_conv_layer_name = 'conv3d_3'\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2, 3))\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "model.layers[-1].activation=None\n",
        "img_array=np.expand_dims(processed_volume,axis=0)\n",
        "preds=model.predict(img_array)\n",
        "print(\"predicted\",preds[0])\n",
        "\n",
        "\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "numslices = heatmap.shape[2]\n",
        "for i in range(num_slices):\n",
        "    plt.matshow(np.squeeze(heatmap[:, :, i]))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FBXRHS9sMROs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import zoom\n",
        "def get_resized_heatmap(heatmap, shape):\n",
        "    \"\"\"Resize heatmap to shape\"\"\"\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    upscaled_heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    upscaled_heatmap = zoom(\n",
        "        upscaled_heatmap,\n",
        "        (\n",
        "            shape[0] / upscaled_heatmap.shape[0],\n",
        "            shape[1] / upscaled_heatmap.shape[1],\n",
        "            shape[2] / upscaled_heatmap.shape[2],\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return upscaled_heatmap\n",
        "\n",
        "\n",
        "resized_heatmap = get_resized_heatmap(heatmap, processed_volume.shape)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 20))\n",
        "\n",
        "ax[0].imshow(np.squeeze(processed_volume[:, :, 30]), cmap='bone')\n",
        "img0 = ax[1].imshow(np.squeeze(processed_volume[:, :, 30]), cmap='bone')\n",
        "img1 = ax[1].imshow(np.squeeze(resized_heatmap[:, :, 30]),\n",
        "                    cmap='jet', alpha=0.3, extent=img0.get_extent())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DjusDt-i5aeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bounding_boxes(heatmap, threshold=0.15, otsu=False):\n",
        "    p_heatmap = np.copy(heatmap)\n",
        "    if otsu:\n",
        "        threshold, p_heatmap = cv2.threshold(\n",
        "            heatmap, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    else:\n",
        "        p_heatmap[p_heatmap < threshold * 255] = 0\n",
        "        p_heatmap[p_heatmap >= threshold * 255] = 1\n",
        "\n",
        "    contours = cv2.findContours(p_heatmap, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "\n",
        "    bboxes = []\n",
        "    for c in contours:\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        bboxes.append([x, y, x + w, y + h])\n",
        "\n",
        "    return bboxes\n",
        "\n",
        "\n",
        "def get_bbox_patches(bboxes, color='r', linewidth=2):\n",
        "    patches = []\n",
        "    for bbox in bboxes:\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        patches.append(\n",
        "            Rectangle(\n",
        "                (x1, y1),\n",
        "                x2 - x1,\n",
        "                y2 - y1,\n",
        "                edgecolor=color,\n",
        "                facecolor='none',\n",
        "                linewidth=linewidth,\n",
        "            )\n",
        "        )\n",
        "    return patches\n",
        "import cv2\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 20))\n",
        "ax[0].imshow(np.squeeze(processed_volume[:, :, 35]), cmap='bone')\n",
        "img0 = ax[1].imshow(np.squeeze(processed_volume[:, :, 35]), cmap='bone')\n",
        "img1 = ax[1].imshow(np.squeeze(resized_heatmap[:, :, 35]),\n",
        "                    cmap='jet', alpha=0.3, extent=img0.get_extent())\n",
        "bboxes = get_bounding_boxes(np.squeeze(resized_heatmap[:, :, 35]))\n",
        "patches = get_bbox_patches(bboxes)\n",
        "for patch in patches:\n",
        "    ax[1].add_patch(patch)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "joWl6L55bD80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LT5DNoxSfIYT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}