{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gv-JOzbi3alh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import codecs\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import ast\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_Q7xVbob3l2Q",
        "outputId": "89a82f4d-bf63-47c0-cc39-be48facd9205"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 question  \\\n",
              "764408  you need to work on your advertising all video...   \n",
              "1991    cable amp internet out all day called cs x is ...   \n",
              "857358  i think i am done with they are really playing...   \n",
              "15701   will hand this book in at paddington found on ...   \n",
              "626333  tried to book a room money deducted shows fail...   \n",
              "\n",
              "                                                answer_in  \\\n",
              "764408  <start> we apologize for the frustration this ...   \n",
              "1991    <start> sorry our tech never came i can check ...   \n",
              "857358  <start> we can definitely take a look send us ...   \n",
              "15701   <start> hi cameron thanks for confirming i wil...   \n",
              "626333  <start> hi there we are sorry to hear about th...   \n",
              "\n",
              "                                               answer_out  \n",
              "764408  we apologize for the frustration this might be...  \n",
              "1991    sorry our tech never came i can check the acco...  \n",
              "857358  we can definitely take a look send us a dm wit...  \n",
              "15701   hi cameron thanks for confirming i will re twe...  \n",
              "626333  hi there we are sorry to hear about this can y...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bb456c0-4bd9-404a-a134-5940fb7f7858\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_in</th>\n",
              "      <th>answer_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>764408</th>\n",
              "      <td>you need to work on your advertising all video...</td>\n",
              "      <td>&lt;start&gt; we apologize for the frustration this ...</td>\n",
              "      <td>we apologize for the frustration this might be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>cable amp internet out all day called cs x is ...</td>\n",
              "      <td>&lt;start&gt; sorry our tech never came i can check ...</td>\n",
              "      <td>sorry our tech never came i can check the acco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857358</th>\n",
              "      <td>i think i am done with they are really playing...</td>\n",
              "      <td>&lt;start&gt; we can definitely take a look send us ...</td>\n",
              "      <td>we can definitely take a look send us a dm wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15701</th>\n",
              "      <td>will hand this book in at paddington found on ...</td>\n",
              "      <td>&lt;start&gt; hi cameron thanks for confirming i wil...</td>\n",
              "      <td>hi cameron thanks for confirming i will re twe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626333</th>\n",
              "      <td>tried to book a room money deducted shows fail...</td>\n",
              "      <td>&lt;start&gt; hi there we are sorry to hear about th...</td>\n",
              "      <td>hi there we are sorry to hear about this can y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bb456c0-4bd9-404a-a134-5940fb7f7858')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bb456c0-4bd9-404a-a134-5940fb7f7858 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bb456c0-4bd9-404a-a134-5940fb7f7858');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3aa6242-a600-4318-8711-7b49c5fab45c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3aa6242-a600-4318-8711-7b49c5fab45c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3aa6242-a600-4318-8711-7b49c5fab45c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import joblib\n",
        "train = joblib.load(\"/content/drive/MyDrive/mmm/train\")\n",
        "validation = joblib.load(\"/content/drive/MyDrive/mmm/validation\")\n",
        "train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5RxkPcUv3qAY"
      },
      "outputs": [],
      "source": [
        "tknizer_q = Tokenizer(filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_q.fit_on_texts(train['question'].values)\n",
        "tknizer_a = Tokenizer(filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_a.fit_on_texts(train['answer_in'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-_yagNd3r40",
        "outputId": "9317b4ca-8d23-430f-cb64-a1a77b22fbe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139809\n",
            "57128\n"
          ]
        }
      ],
      "source": [
        "q_word_idx = tknizer_q.word_index\n",
        "q_idx_word = {v: k for k, v in q_word_idx.items()}\n",
        "\n",
        "a_word_idx = tknizer_a.word_index\n",
        "a_idx_word = {v: k for k, v in a_word_idx.items()}\n",
        "\n",
        "print(len(q_word_idx.keys()))\n",
        "print(len(a_word_idx.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56QVSPRb3t0P",
        "outputId": "aed95aa8-6223-41a3-a82f-96bab4a3fb8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['<start> we apologize for the frustration this might be causing we appreciate your feedback and we will share it with our advertising teams <end>',\n",
              "       '<start> sorry our tech never came i can check the account if you could dm your address or acct ps',\n",
              "       '<start> we can definitely take a look send us a dm with your email address so we can follow up',\n",
              "       ...,\n",
              "       '<start> hi stephen we want to follow up can you please dm us the guests information so that we can reach out to her and review the case',\n",
              "       '<start> hello kirsty i am very sorry to hear you have not received your early access code can you dm us your full name email address and full home address details which are linked to your account please so we can look into this please ty ross',\n",
              "       '<start> that is not the experience we would hope you have send us a dm and let us know more details we will get started there'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train['answer_in'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGNr6kei3v4A",
        "outputId": "f41b70c3-5f68-416c-d1cb-b47b9831f9b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 30128)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "a_word_idx['<start>'], a_word_idx['<end>']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8O8TsDqD3yeB"
      },
      "outputs": [],
      "source": [
        "vocab_size_a = len(a_word_idx.keys())\n",
        "vocab_size_q = len(q_word_idx.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6vCPNpvM30Aw"
      },
      "outputs": [],
      "source": [
        "#This class represents a custom dataset for the sequence-to-sequence model.\n",
        "#It takes data (presumably a DataFrame), along with tokenizers (tknizer_q and tknizer_a) for questions and answers.\n",
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_q, tknizer_a):\n",
        "        self.encoder_inps = data['question'].values\n",
        "        self.decoder_inps = data['answer_in'].values\n",
        "        self.decoder_outs = data['answer_out'].values\n",
        "        self.tknizer_q = tknizer_q\n",
        "        self.tknizer_a = tknizer_a\n",
        "\n",
        "#The __getitem__ method converts text sequences to sequences of integers using tokenizers and pads them to a fixed length (27 in this case).\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_q.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_a.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_a.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq,maxlen=27, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq,maxlen=27, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq,maxlen=27, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "#The __len__ method returns the total number of samples in the dataset.\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "\n",
        "\n",
        "#This class is a custom data loader inheriting from tf.keras.utils.Sequence, which is suitable for generating data batches in parallel while training.\n",
        "#It takes a dataset (an instance of the Dataset class) and a batch_size as parameters.\n",
        "class Dataloder(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "#The __getitem__ method retrieves a batch of data from the dataset, stacks the samples, and returns a tuple of input and output sequences.\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "#The __len__ method returns the total number of batches in an epoch.\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "#The on_epoch_end method shuffles the indexes at the end of each epoch.\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0BV4eij31ts",
        "outputId": "de40da4c-9841-431c-dfd9-2f72fbb1e845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 27) (128, 27) (128, 27)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Dataset(train, tknizer_q, tknizer_a)\n",
        "test_dataset  = Dataset(validation, tknizer_q, tknizer_a)\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=128)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=128)\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "D48mBAgb33M4"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "    def __init__(self, ques_vocab_size, embedding_dim, encoder_input_length, lstm_units):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        super().__init__(name=\"encode_model_attention\")\n",
        "        self.ques_vocab_size = ques_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.encoder_input_length = encoder_input_length\n",
        "        self.embedding = Embedding(input_dim=self.ques_vocab_size, output_dim=self.embedding_dim, input_length=self.encoder_input_length,\\\n",
        "                  mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.LSTM = LSTM(self.lstm_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "    def call(self,input_sequence):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
        "        '''\n",
        "        input_embeddings = self.embedding(input_sequence)\n",
        "        self.lstm_output, self.lstm_state_h, self.lstm_state_c = self.LSTM(input_embeddings)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "\n",
        "\n",
        "    def initialize_states(self,batch_size):\n",
        "        '''\n",
        "        Given a batch size it will return intial hidden state and intial cell state.\n",
        "        If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "        '''\n",
        "        lstm_state_h = tf.zeros([batch_size, self.lstm_size])\n",
        "        lstm_state_c = tf.zeros([batch_size, self.lstm_size])\n",
        "\n",
        "        return lstm_state_h, lstm_state_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Igm5PDxK343d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import *\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "    '''\n",
        "    def __init__(self, att_units):\n",
        "\n",
        "        super().__init__(name=\"Attention_Bahdanau\")\n",
        "        self.K = 100\n",
        "        self.dense_1 = Dense(self.K, activation='relu')\n",
        "        self.dense_2 = Dense(self.K, activation='relu')\n",
        "        self.dense_3 = Dense(1, activation='relu')\n",
        "\n",
        "\n",
        "    def call(self, decoder_hidden_state, encoder_output):\n",
        "        '''\n",
        "          Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "          * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "            Multiply the score function with your encoder_outputs to get the context vector.\n",
        "            Function returns context vector and attention weights(softmax - scores)\n",
        "        '''\n",
        "\n",
        "        k1 = self.dense_1(encoder_output)\n",
        "        k2 =  self.dense_2(decoder_hidden_state)\n",
        "        add = tf.keras.layers.Add()([k1, k2])\n",
        "        tanh = tf.keras.layers.Activation(activation=\"tanh\")(add)\n",
        "        ei = self.dense_3(tanh)\n",
        "        ei = tf.squeeze(ei,-1)\n",
        "        alphas = Softmax()(ei)\n",
        "        alphas = tf.expand_dims(alphas, axis=-1)\n",
        "        mull = tf.keras.layers.Multiply()([encoder_output, alphas])\n",
        "        context_vec = tf.reduce_mean(mull, axis=-2)\n",
        "        return context_vec, alphas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uR2YL4zx36ej"
      },
      "outputs": [],
      "source": [
        "class OneStepDecoder(tf.keras.Model):\n",
        "    def __init__(self,ans_vocab_size, embedding_dim, decoder_input_length, lstm_units, attention_units):\n",
        "        super().__init__(name=\"OneStepDecoder\")\n",
        "        # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "\n",
        "        self.lstm_units = lstm_units\n",
        "        self.attention_units = attention_units\n",
        "        self.attention = Attention(attention_units)\n",
        "        self.embedding = Embedding(input_dim = ans_vocab_size, output_dim = embedding_dim, input_length = decoder_input_length,\n",
        "                                   mask_zero=True, trainable=True )\n",
        "        #weights=[embedding_matrix]\n",
        "\n",
        "        self.lstm = LSTM(self.lstm_units, return_sequences=True, return_state=True,name=\"OneStepDecoder_LSTM\")\n",
        "        self.dense = Dense(ans_vocab_size, activation='softmax')\n",
        "\n",
        "\n",
        "    def call(self, input_to_decoder, encoder_output, state_h, state_c):\n",
        "        '''\n",
        "             One step decoder mechanisim step by step:\n",
        "          A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "          B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "          C. Concat the context vector with the step A output\n",
        "          D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "          E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "          F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "        '''\n",
        "        #adding attention information to embeddings now\n",
        "        embeddings = self.embedding(input_to_decoder)\n",
        "        context_vector, attention_weights = self.attention(state_h, encoder_output)\n",
        "        attention_embeddings = tf.concat([tf.expand_dims(context_vector, 1), embeddings], axis=-1)\n",
        "\n",
        "        x, state_h, state_c = self.lstm(attention_embeddings, initial_state=[state_h, state_c])\n",
        "\n",
        "        output = self.dense(x)\n",
        "\n",
        "        output = tf.squeeze(output,1)\n",
        "\n",
        "        return output, state_h, state_c, attention_weights, context_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pUat2csq379X"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, ans_vocab_size, embedding_dim, decoder_input_length, lstm_units, attention_units):\n",
        "        #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "        super().__init__(name=\"Decode_Attention\")\n",
        "        self.ans_vocab_size = ans_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.decoder_input_length = decoder_input_length\n",
        "        self.lstm_units = lstm_units\n",
        "        self.attention_units = attention_units\n",
        "        self.onestepdecoder = OneStepDecoder(self.ans_vocab_size, \\\n",
        "                                             self.embedding_dim, \\\n",
        "                                             self.decoder_input_length, \\\n",
        "                                             self.lstm_units, self.attention_units)\n",
        "\n",
        "    def call(self, input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "\n",
        "        #Iterate till the length of the decoder input\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # Store the output in tensorarray\n",
        "        # Return the tensor array\n",
        "\n",
        "        all_outputs = tf.TensorArray(tf.float32, size=27, name=\"output_arrays\")\n",
        "        for timestep in range(27):\n",
        "            output,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector = self.onestepdecoder(\\\n",
        "                                input_to_decoder[:, timestep:timestep+1],encoder_output,\\\n",
        "                                decoder_hidden_state,decoder_cell_state\n",
        "                               )\n",
        "\n",
        "            all_outputs = all_outputs.write(timestep, output)\n",
        "        all_outputs = tf.transpose(all_outputs.stack(), [1,0,2])\n",
        "        return all_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OnI2cG8a39mw"
      },
      "outputs": [],
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "    def __init__(self,ques_vocab_size, ans_vocab_size, encoder_input_length, dencoder_input_length, emb_dim, lstm_units, attention_units):\n",
        "        #Intialize objects from encoder decoder\n",
        "        super().__init__(name=\"Encoder_Decoder_Attention_model\")\n",
        "\n",
        "        self.encoder = Encoder(ques_vocab_size, emb_dim, encoder_input_length, lstm_units )\n",
        "        self.decoder = Decoder(ans_vocab_size, emb_dim, dencoder_input_length, lstm_units, attention_units)\n",
        "\n",
        "    def call(self,data):\n",
        "        #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "        # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "        # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "        # return the decoder output\n",
        "        input_q, input_a = data[0], data[1]\n",
        "        encoder_output, encoder_h, encoder_c = self.encoder(input_q)\n",
        "        decoder_output = self.decoder(input_a, encoder_output, encoder_h, encoder_c)\n",
        "        return decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jv497DoD3_L3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, TensorBoard, LearningRateScheduler\n",
        "from sklearn.metrics import recall_score, f1_score, roc_curve, auc\n",
        "import datetime\n",
        "\n",
        "filepath=\"model_save_attention_4/weights-{epoch:02d}-{val_loss:.2f}\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', save_format=\"tf\", save_freq=\"epoch\",  verbose=1, save_best_only=True, mode='auto')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PqItbJ14A09",
        "outputId": "ce95e0df-0c7e-48da-98d6-e974c1b1b8fe"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4964/4964 [==============================] - ETA: 0s - loss: 2.8514 - accuracy: 0.5082\n",
            "Epoch 1: val_loss improved from inf to 2.13657, saving model to model_save_attention_4/weights-01-2.14\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:<__main__.Attention object at 0x7f8a572c6950> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4964/4964 [==============================] - 3645s 723ms/step - loss: 2.8514 - accuracy: 0.5082 - val_loss: 2.1366 - val_accuracy: 0.5906\n",
            "Epoch 2/10\n",
            "4964/4964 [==============================] - ETA: 0s - loss: 1.9995 - accuracy: 0.6106\n",
            "Epoch 2: val_loss improved from 2.13657 to 1.90270, saving model to model_save_attention_4/weights-02-1.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:<__main__.Attention object at 0x7f8a572c6950> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4964/4964 [==============================] - 3610s 727ms/step - loss: 1.9995 - accuracy: 0.6106 - val_loss: 1.9027 - val_accuracy: 0.6247\n",
            "Epoch 3/10\n",
            "4964/4964 [==============================] - ETA: 0s - loss: 1.8191 - accuracy: 0.6351\n",
            "Epoch 3: val_loss improved from 1.90270 to 1.80878, saving model to model_save_attention_4/weights-03-1.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:<__main__.Attention object at 0x7f8a572c6950> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4964/4964 [==============================] - 3622s 730ms/step - loss: 1.8191 - accuracy: 0.6351 - val_loss: 1.8088 - val_accuracy: 0.6391\n",
            "Epoch 4/10\n",
            " 596/4964 [==>...........................] - ETA: 47:38 - loss: 1.7217 - accuracy: 0.6476"
          ]
        }
      ],
      "source": [
        "ques_vocab_size = vocab_size_q + 1\n",
        "ans_vocab_size = vocab_size_a + 1\n",
        "encoder_input_length = 27\n",
        "dencoder_input_length = 27\n",
        "lstm_units = 512\n",
        "attention_units = 512\n",
        "emb_dim = 100\n",
        "\n",
        "model_attention = encoder_decoder(ques_vocab_size,\n",
        "                                  ans_vocab_size,\n",
        "                                  encoder_input_length,\n",
        "                                  dencoder_input_length,\n",
        "                                  emb_dim,\n",
        "                                  lstm_units,\n",
        "                                  attention_units)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model_attention.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "train_steps=train.shape[0]//128\n",
        "valid_steps=validation.shape[0]//128\n",
        "history_dot = model_attention.fit(train_dataloader, \\\n",
        "                                      steps_per_epoch=train_steps, \\\n",
        "                                      epochs=10, \\\n",
        "                                      validation_data=test_dataloader, \\\n",
        "                                      validation_steps=valid_steps,\n",
        "                                      callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kjRu8TF4C8B"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model_attention)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}