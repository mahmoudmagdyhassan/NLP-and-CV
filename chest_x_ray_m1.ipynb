{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "name": "chest-x_ray-m1.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYThzPHEaN_F"
      },
      "outputs": [],
      "source": [
        "!wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz\n",
        "!wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#from tqdm.notebook import tqdm\n",
        "import os\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from collections import defaultdict\n",
        "#import tensorflow as tf"
      ],
      "metadata": {
        "id": "IAsblbZGaRhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "file_path = '/content/NLMCXR_png.tgz'  # Replace with the actual path to your file\n",
        "\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    tar.extractall('/content/images')  # Replace with the desired extraction directory\n"
      ],
      "metadata": {
        "id": "DRMfO7w6hrqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "file_path = '/content/NLMCXR_reports.tgz'  # Replace with the actual path to your file\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    tar.extractall('/content/reports')  # Replace with the desired extraction directory\n"
      ],
      "metadata": {
        "id": "_4X0Li5AiNHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"image_id\", \"caption\", \"comparison\", \"indication\", \"findings\", \"impression\",\"height\",\"width\"]\n",
        "df = pd.DataFrame(columns = columns)"
      ],
      "metadata": {
        "id": "_uld88o5ZdSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(\"/content/images\"))"
      ],
      "metadata": {
        "id": "_v0Mm1_gkFHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import os\n",
        "import pandas as pd\n",
        "for file in tqdm(os.listdir(\"/content/reports/ecgen-radiology/\")):\n",
        "    if file.endswith(\".xml\"):\n",
        "        k = \"/content/reports/ecgen-radiology/\"\n",
        "        path = k + file\n",
        "        mytree = ET.parse(path)# parsing xml report\n",
        "        comparision = mytree.find(\".//AbstractText[@Label='COMPARISON']\").text # extracting comaparison text\n",
        "        indication = mytree.find(\".//AbstractText[@Label='INDICATION']\").text #extracting indication text\n",
        "        findings = mytree.find(\".//AbstractText[@Label='FINDINGS']\").text # extracting findings text\n",
        "        impression = mytree.find(\".//AbstractText[@Label='IMPRESSION']\").text  # extracting impression text\n",
        "\n",
        "        mytree = ET.parse(path)\n",
        "        for x in mytree.findall(\"parentImage\"):\n",
        "            image_id = x.attrib['id']+\".png\"\n",
        "            filename = '/content/images/' + image_id\n",
        "            image = cv2.imread(filename) # reading image\n",
        "\n",
        "            height, width, channels = image.shape\n",
        "            caption = '' if x.find('caption').text is None else x.find('caption').text\n",
        "\n",
        "            df = df.append(pd.Series([image_id, caption, comparision, indication, findings, impression,height,width],\n",
        "                                                         index = columns), ignore_index = True)"
      ],
      "metadata": {
        "id": "wHlUC43f0bV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "yHW2qMAlmBJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "v_djxLDOndKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['image_id']=='CXR1005_IM-0006-3003.png']"
      ],
      "metadata": {
        "id": "7HJXyX3A1pQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "Y_oJFk4M3Dst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def absolute_path(x):\n",
        "    '''Makes the path absolute '''\n",
        "    x = '/content/images/'+ x\n",
        "    return x\n",
        "\n",
        "df['Image_path'] = df['image_id'].apply(lambda x : absolute_path(x)) # making the paths absolute"
      ],
      "metadata": {
        "id": "X6xHLXbS1ypS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "op-tV8hJ3HI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns\n",
        "df = df.rename(columns={\n",
        "    'image_id': 'image_id',\n",
        "    'eCitation': 'caption',\n",
        "    'COMPARISON': 'comparison',\n",
        "    'INDICATION': 'indication',\n",
        "    'FINDINGS': 'findings',\n",
        "    'IMPRESSION': 'impression',\n",
        "    'height': 'height',\n",
        "    'width': 'width',\n",
        "    'Image_path': 'Image_path'\n",
        "})\n",
        "\n",
        "# Optional: Reorder columns\n",
        "df = df[['image_id', 'caption', 'comparison', 'indication', 'findings', 'impression', 'height', 'width', 'Image_path']]\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "bFcnWPmr4Czv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['image_id']=='CXR1_1_IM-0001-3001.png']"
      ],
      "metadata": {
        "id": "PtQrx2PFcQ95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "aTUDpq7TcWM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 1\n",
        "fig = plt.figure(figsize=(15, 35))\n",
        "\n",
        "for filename in df['Image_path'].values[95:100]:\n",
        "    findings = list(df[\"findings\"].loc[df[\"Image_path\"] == filename].values)\n",
        "\n",
        "    img = cv2.imread(filename)\n",
        "    if img is None:\n",
        "        print(f\"Error loading image: {filename}\")\n",
        "        continue  # Skip to the next iteration if the image cannot be loaded\n",
        "\n",
        "    ax = fig.add_subplot(5, 2, count, xticks=[], yticks=[])\n",
        "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n",
        "    count += 1\n",
        "\n",
        "    ax = fig.add_subplot(5, 2, count)\n",
        "    plt.axis('off')\n",
        "    ax.plot()\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, len(findings))\n",
        "\n",
        "    for i, f in enumerate(findings):\n",
        "        ax.text(0, i, f, fontsize=20)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nrLMqqMZ3Jhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,7))\n",
        "img = cv2.imread(df['Image_path'].values[20])\n",
        "plt.imshow(img)\n",
        "plt.title(df['Image_path'].values[20])\n",
        "\n",
        "df['findings'].values[20]"
      ],
      "metadata": {
        "id": "K6bW86TbSfyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting height\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(121)\n",
        "plt.title('Height Plot')\n",
        "plt.ylabel('Heights')\n",
        "plt.xlabel('--Images--')\n",
        "sns.scatterplot(x=range(len(df.height.values)), y=df.height.values)\n",
        "\n",
        "# Plotting width\n",
        "plt.subplot(122)\n",
        "plt.title('Width Plot')\n",
        "plt.ylabel('Widths')\n",
        "plt.xlabel('--Images--')\n",
        "sns.scatterplot(x=range(len(df.width.values)), y=df.width.values)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZcTd9h6i3bf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "USEsMQq14jUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['image_id','findings','height','width','Image_path']]"
      ],
      "metadata": {
        "id": "qczsKlf25Biw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "LSXQKcbI5Seo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna(axis=0) # drop all missing value rows"
      ],
      "metadata": {
        "id": "Vz92dRIJ5W3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,7))\n",
        "img = cv2.imread(data['Image_path'].values[5])\n",
        "plt.imshow(img)\n",
        "plt.title(data['Image_path'].values[5])\n",
        "\n",
        "data['findings'].values[5]"
      ],
      "metadata": {
        "id": "wIrYcscK5cPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.Image_path"
      ],
      "metadata": {
        "id": "atDrshmF5i6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(1)"
      ],
      "metadata": {
        "id": "wH3E1Zur8wjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = {}\n",
        "findings = {}\n",
        "\n",
        "# Assuming `data` is a DataFrame with columns 'Image_path' and 'findings'\n",
        "for img, fin in data[['Image_path', 'findings']].values:\n",
        "    # Split the image path to get the filename and extract information\n",
        "    a = img.split('.')\n",
        "    file_type = a[-1]  # Get the file type (e.g., 'png')\n",
        "\n",
        "    # Further split the filename to extract relevant information\n",
        "    a = a[0].split('-')\n",
        "    a.pop(len(a)-1)\n",
        "    a = '-'.join(e for e in a)  # Join the remaining parts with '-'\n",
        "\n",
        "    # Check if the key already exists in the 'images' dictionary\n",
        "    if a not in images.keys():\n",
        "        # If not, create a new entry with count 1 and store findings\n",
        "        images[a] = 1\n",
        "        findings[a] = fin\n",
        "    else:\n",
        "        # If the key already exists, increment the count and update findings\n",
        "        images[a] += 1\n",
        "        findings[a] = fin\n"
      ],
      "metadata": {
        "id": "ckysxYmi56bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images"
      ],
      "metadata": {
        "id": "8u9msSA46xtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images['/content/images/CXR368_IM-1832'],findings['/content/images/CXR368_IM-1832']"
      ],
      "metadata": {
        "id": "hC6ke2sv6IdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images['/content/images/CXR305_IM-1420'],findings['/content/images/CXR305_IM-1420']"
      ],
      "metadata": {
        "id": "8-QvoVjWASma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total Number of Unique_IDs :', len(images.keys()))"
      ],
      "metadata": {
        "id": "kQjlOHAF6Nlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Number of Images  per patients')\n",
        "sns.countplot(list(images.values()))"
      ],
      "metadata": {
        "id": "oqoJL7Ts7KPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(data):\n",
        "    persons = list(data.keys())\n",
        "    persons_train = persons[:2500]\n",
        "    persons_cv = persons[2500:3000]\n",
        "    persons_test = persons[3000:3350]\n",
        "    return persons_train, persons_cv, persons_test\n",
        "\n",
        "images_train, images_cv, images_test = train_test_split(images)"
      ],
      "metadata": {
        "id": "rCGRwlH9-H2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_train"
      ],
      "metadata": {
        "id": "gDRn5cyq-x_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combining_images(image_set):\n",
        "\n",
        "    image_per_person = defaultdict(list)  # creating a list of dictionary to store all the image paths\n",
        "                                            #corresponding to a person_id\n",
        "    for pid in image_set:\n",
        "        for img in data['Image_path'].values:\n",
        "            if pid in img:\n",
        "                image_per_person[pid].append(img)\n",
        "            else:\n",
        "                continue\n",
        "    return image_per_person"
      ],
      "metadata": {
        "id": "0rN9g8SK_G1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_per_person_train = combining_images(images_train)\n",
        "img_per_person_cv = combining_images(images_cv)\n",
        "img_per_person_test = combining_images(images_test)"
      ],
      "metadata": {
        "id": "NyLhp2Wo_OC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_per_person_train"
      ],
      "metadata": {
        "id": "lwORATs4BDGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_per_person_train['/content/images/CXR427_IM-2070']"
      ],
      "metadata": {
        "id": "q2kgk91qA44H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(file):\n",
        "    img = cv2.imread(file)\n",
        "    return img"
      ],
      "metadata": {
        "id": "J6Q0_vjzBA6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just checking the ID which has 4 images\n",
        "for k,v in images.items():\n",
        "    if v == 4:\n",
        "        print(k)\n",
        "        break\n"
      ],
      "metadata": {
        "id": "OGzeWXH9BjVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_per_person_train"
      ],
      "metadata": {
        "id": "-8deppz5fgy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "plt.subplot(221)\n",
        "plt.imshow(load_image('/content/images/CXR2646_IM-1131-1001.png'))\n",
        "plt.title('/content/images/CXR2646_IM-1131-1001.png')\n",
        "plt.subplot(222)\n",
        "plt.imshow(load_image('/content/images/CXR1001_IM-0004-1001.png'))\n",
        "plt.title('/content/images/CXR1001_IM-0004-1001.png')\n",
        "plt.subplot(223)\n",
        "plt.imshow(load_image('/content/images/CXR1003_IM-0005-2002.png'))\n",
        "plt.title('/content/images/CXR1003_IM-0005-2002.png')\n",
        "plt.subplot(224)\n",
        "plt.imshow(load_image('/content/images/CXR1005_IM-0006-1001.png'))\n",
        "plt.title('/content/images/CXR1005_IM-0006-1001.png')"
      ],
      "metadata": {
        "id": "nHnXXL00Bkce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def create_data(image_per_person):\n",
        "    # new dataset\n",
        "    person_id, image1, image2, report = [],[],[],[]\n",
        "    for pid, imgs in image_per_person.items():   #contains pid and the images associated with that pid\n",
        "\n",
        "        if len(imgs) == 1:\n",
        "            image1.append(imgs[0])\n",
        "            image2.append(imgs[0])\n",
        "            person_id.append(pid)\n",
        "            report.append(findings[pid])\n",
        "        else:\n",
        "            num = 0\n",
        "            a = itertools.combinations(imgs, 2)\n",
        "            for i in a:\n",
        "                image1.append(i[0])\n",
        "                image2.append(i[1])\n",
        "                person_id.append(pid + '_' + str(num))\n",
        "                report.append(findings[pid])\n",
        "                num += 1\n",
        "    data = pd.DataFrame()\n",
        "    data['Person_id'] = person_id\n",
        "    data['Image1'] = image1\n",
        "    data['Image2'] = image2\n",
        "    data['Report'] = report\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "RhZXiW-MCY9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = create_data(img_per_person_train)\n",
        "test = create_data(img_per_person_test)\n",
        "cv = create_data(img_per_person_cv)"
      ],
      "metadata": {
        "id": "27a0iINKDB7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(2)"
      ],
      "metadata": {
        "id": "pYzrr8rtDExk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('train.csv')\n",
        "test.to_csv('test.csv')\n",
        "cv.to_csv('cv.csv')"
      ],
      "metadata": {
        "id": "WMDux71ADOoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preporcessing text data¶"
      ],
      "metadata": {
        "id": "zOufm4leDkq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lowercase(text):\n",
        "    '''Converts to lowercase'''\n",
        "    new_text = []\n",
        "    for line in text:\n",
        "        new_text.append(line.lower())\n",
        "    return new_text\n",
        "\n",
        "def decontractions(text):\n",
        "    '''Performs decontractions in the doc'''\n",
        "    new_text = []\n",
        "    for phrase in text:\n",
        "        phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "        phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "        phrase = re.sub(r\"couldn\\'t\", \"could not\", phrase)\n",
        "        phrase = re.sub(r\"shouldn\\'t\", \"should not\", phrase)\n",
        "        phrase = re.sub(r\"wouldn\\'t\", \"would not\", phrase)\n",
        "        # general\n",
        "        phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "        phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "        phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "        phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "        phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "        phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "        phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "        phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "        phrase = re.sub(r\"\\*+\", \"abuse\", phrase)\n",
        "        new_text.append(phrase)\n",
        "\n",
        "    return new_text\n",
        "\n",
        "def rem_punctuations(text):\n",
        "    '''Removes punctuations'''\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>/?@#$%^&*~''' # full stop is not removed\n",
        "    new_text = []\n",
        "    for line in text:\n",
        "        for char in line:\n",
        "            if char in punctuations:\n",
        "                line = line.replace(char, \"\")\n",
        "        new_text.append(' '.join(e for e in line.split()))\n",
        "    return new_text\n",
        "\n",
        "def rem_numbers(text):\n",
        "    '''Removes numbers and irrelevant text like xxxx*'''\n",
        "    new_text = []\n",
        "    for line in text:\n",
        "        temp = re.sub(r'x*','',line)\n",
        "        new_text.append(re.sub(r'\\d','',temp))\n",
        "    return new_text\n",
        "\n",
        "def words_filter(text):\n",
        "    '''Removes words less than 2 characters except no and ct'''\n",
        "    new_text = []\n",
        "    for line in text:\n",
        "        temp = line.split()\n",
        "        temp2 = []\n",
        "        for word in temp:\n",
        "            if  len(word) <=2 and word != 'no' and word != 'ct':\n",
        "                continue\n",
        "            else:\n",
        "                temp2.append(word)\n",
        "        new_text.append(' '.join(e for e in temp2))\n",
        "    return new_text\n",
        "\n",
        "def multiple_fullstops(text):\n",
        "    ''' Removes multiple full stops from the text'''\n",
        "    new_text = []\n",
        "    for line in text:\n",
        "        new_text.append(re.sub(r'\\.\\.+', '.', line))\n",
        "    return new_text\n",
        "\n",
        "def fullstops(text):\n",
        "    new_text = []\n",
        "    for line in text:\n",
        "        new_text.append(re.sub('\\.', ' .', line))\n",
        "    return new_text\n",
        "\n",
        "def multiple_spaces(text):\n",
        "    new_text = []\n",
        "    for line in text:\n",
        "        new_text.append(' '.join(e for e in line.split()))\n",
        "    return new_text\n",
        "\n",
        "def separting_startg_words(text):\n",
        "    new_text = []\n",
        "    for line in text:\n",
        "        temp = []\n",
        "        words = line.split()\n",
        "        for i in words:\n",
        "            if i.startswith('.') == False:\n",
        "                temp.append(i)\n",
        "            else:\n",
        "                w = i.replace('.','. ')\n",
        "                temp.append(w)\n",
        "        new_text.append(' '.join(e for e in temp))\n",
        "    return new_text\n",
        "\n",
        "def rem_apostrophes(text):\n",
        "    new_text = []\n",
        "    for line in text:\n",
        "        new_text.append(re.sub(\"'\",'',line))\n",
        "    return new_text"
      ],
      "metadata": {
        "id": "hE2RMYgEDZ4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text):\n",
        "    '''Combines all the preprocess functions'''\n",
        "    new_text = lowercase(text)\n",
        "    new_text = decontractions(new_text)\n",
        "    new_text = rem_punctuations(new_text)\n",
        "    new_text = rem_numbers(new_text)\n",
        "    new_text = words_filter(new_text)\n",
        "    new_text = multiple_fullstops(new_text)\n",
        "    new_text = fullstops(new_text)\n",
        "    new_text = multiple_spaces(new_text)\n",
        "    new_text = separting_startg_words(new_text)\n",
        "    new_text = rem_apostrophes(new_text)\n",
        "    return new_text"
      ],
      "metadata": {
        "id": "F5fBEXWCDwv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['Report'] = text_preprocessing(train['Report'])\n",
        "test['Report'] = text_preprocessing(test['Report'])\n",
        "cv['Report'] = text_preprocessing(cv['Report'])"
      ],
      "metadata": {
        "id": "_qVJKyIUD0oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "13kqTNFXD5zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('processed_train.csv')\n",
        "test.to_csv('processed_test.csv')\n",
        "cv.to_csv('processed_cv.csv')"
      ],
      "metadata": {
        "id": "8Rnr_ePdD8UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = [len(e.split()) for e in train['Report'].values]  # Number of words in each report"
      ],
      "metadata": {
        "id": "V5xpCcPWD_0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('maximum word in a report is :',max(l))"
      ],
      "metadata": {
        "id": "8Jg1JkuuEGp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Number of Words per Report')\n",
        "sns.scatterplot(x=range(train.shape[0]), y=l)\n",
        "plt.ylabel('Number of words')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I8WBr2n1EI7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "def show_wordcloud(data, title = None):\n",
        "    wordcloud = WordCloud(background_color='black',max_words=800,max_font_size=60,scale=3,random_state=1 ).generate(' '.join(data.astype(str)))\n",
        "\n",
        "    fig = plt.figure(1, figsize=(12, 15))\n",
        "    plt.axis('off')\n",
        "    if title:\n",
        "        fig.suptitle(title, fontsize=20)\n",
        "        fig.subplots_adjust(top=2.3)\n",
        "\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.show()\n",
        "\n",
        "show_wordcloud(train['Report'])"
      ],
      "metadata": {
        "id": "9tHkLYL2EN2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countword = train['Report'].str.split().apply(len).value_counts()\n",
        "countword[:].plot(kind='bar',figsize=(20,5) , title = 'Words for each findings review')"
      ],
      "metadata": {
        "id": "0qN52SrAEkKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remodelling(x):\n",
        "    '''adds start and end tokens to a sentence '''\n",
        "    return 'startseq' + ' ' + x + ' ' + 'endseq'"
      ],
      "metadata": {
        "id": "MdrXtRD0Et7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['Report'] = train['Report'].apply(lambda x : remodelling(x))\n",
        "test['Report'] = test['Report'].apply(lambda x : remodelling(x))\n",
        "cv['Report'] = cv['Report'].apply(lambda x : remodelling(x))"
      ],
      "metadata": {
        "id": "i32dXN-NE1Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['Report'][1]"
      ],
      "metadata": {
        "id": "j6-aJb5AE-vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the cleaned data(STRUCTURED DATA)\n",
        "train.to_csv('Final_Train_Data.csv', index=False)\n",
        "test.to_csv('Final_Test_Data.csv', index=False)\n",
        "cv.to_csv('Final_CV_Data.csv', index=False)"
      ],
      "metadata": {
        "id": "6UAEtFM7E3lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "3P6iNaQfFNYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import densenet\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Conv2D\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Embedding, Conv2D, Concatenate, Flatten, Add, Dropout, GRU\n",
        "import random\n",
        "import datetime\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "id": "XtWPNNl_aXtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chexNet = densenet.DenseNet121(include_top=False, weights = None,   input_shape=(224,224,3), pooling=\"avg\")\n",
        "X = chexNet.output\n",
        "X = Dense(14, activation=\"sigmoid\", name=\"predictions\")(X)\n",
        "model = Model(inputs=chexNet.input, outputs=X)\n",
        "\n",
        "! gdown \"https://drive.google.com/u/0/uc?id=19BllaOvs2x5PLV_vlWMy4i8LapLb2j6b&export=download\"\n",
        "\n"
      ],
      "metadata": {
        "id": "y-WHeHgHIpyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loadind pretrained weights for ChexNet model\n",
        "model.load_weights('/content/brucechou1983_CheXNet_Keras_0.3.0_weights.h5')\n",
        "\n",
        "chexNet = Model(inputs = model.input, outputs = model.layers[-2].output)"
      ],
      "metadata": {
        "id": "T3uX9pqlZ4Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train=pd.read_csv(\"/content/Final_Train_Data.csv\")\n",
        "test=pd.read_csv(\"/content/Final_Test_Data.csv\")\n",
        "cv=pd.read_csv(\"/content/Final_CV_Data.csv\")"
      ],
      "metadata": {
        "id": "D72Zu-TH6j9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "gaD0hTjn7_4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.densenet import preprocess_input\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'train', 'test', and 'cv' are your DataFrames containing image paths and findings\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    # Load the image and resize it to (224, 224)\n",
        "    img = load_img(image_path, target_size=(224, 224))\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = img_to_array(img)\n",
        "    # Expand the dimensions to match the expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    # Preprocess the image (e.g., normalize pixel values)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# Load the pre-trained ChexNet model\n",
        "chexNet = densenet.DenseNet121(include_top=False, weights=None, input_shape=(224, 224, 3), pooling=\"avg\")\n",
        "X = chexNet.output\n",
        "X = Dense(14, activation=\"sigmoid\", name=\"predictions\")(X)\n",
        "model = Model(inputs=chexNet.input, outputs=X)\n",
        "\n",
        "# Load the pre-trained weights for the ChexNet model\n",
        "!gdown \"https://drive.google.com/u/0/uc?id=19BllaOvs2x5PLV_vlWMy4i8LapLb2j6b&export=download\"\n",
        "model.load_weights('/content/brucechou1983_CheXNet_Keras_0.3.0_weights.h5')\n",
        "\n",
        "# Create a modified ChexNet model for feature extraction\n",
        "chexNet = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "\n",
        "Xnet_features = {}\n",
        "\n",
        "# Process the 'train' dataset\n",
        "for key, img1, img2, finding in tqdm(train.values):\n",
        "    i1 = load_and_preprocess_image(img1)\n",
        "    img1_features = chexNet.predict(i1)\n",
        "    i2 = load_and_preprocess_image(img2)\n",
        "    img2_features = chexNet.predict(i2)\n",
        "    input_ = np.concatenate((img1_features, img2_features), axis=1)\n",
        "    Xnet_features[key] = input_\n",
        "\n",
        "# Process the 'test' dataset\n",
        "for key, img1, img2, finding in tqdm(test.values):\n",
        "    i1 = load_and_preprocess_image(img1)\n",
        "    img1_features = chexNet.predict(i1)\n",
        "    i2 = load_and_preprocess_image(img2)\n",
        "    img2_features = chexNet.predict(i2)\n",
        "    input_ = np.concatenate((img1_features, img2_features), axis=1)\n",
        "    Xnet_features[key] = input_\n",
        "\n",
        "# Process the 'cv' dataset\n",
        "for key, img1, img2, finding in tqdm(cv.values):\n",
        "    i1 = load_and_preprocess_image(img1)\n",
        "    img1_features = chexNet.predict(i1)\n",
        "    i2 = load_and_preprocess_image(img2)\n",
        "    img2_features = chexNet.predict(i2)\n",
        "    input_ = np.concatenate((img1_features, img2_features), axis=1)\n",
        "    Xnet_features[key] = input_\n"
      ],
      "metadata": {
        "id": "yeIS4Zw3ajeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "id": "MyKjkeHybATL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/glove.6B.zip"
      ],
      "metadata": {
        "id": "YuF34ENbqQct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train['Person_id']\n",
        "X_test = test['Person_id']\n",
        "X_cv = cv['Person_id']\n",
        "y_train = train['Report']\n",
        "y_test = test['Report']\n",
        "y_cv = cv['Report']\n",
        "\n",
        "cheXnet_Features = Xnet_features"
      ],
      "metadata": {
        "id": "Arfl-j80rOk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now we tokenize our text data and create a emending matrix."
      ],
      "metadata": {
        "id": "ejj1APAnr4gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import pickle\n",
        "\n",
        "# Assuming 'y_train' is a Series containing your text data\n",
        "\n",
        "# Initialize Tokenizer\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(y_train.values)\n",
        "\n",
        "# Set padding size\n",
        "padding_size = 153   # Max length\n",
        "\n",
        "# Calculate vocabulary size\n",
        "vocab_size = len(tokenizer.word_index.keys()) + 1\n",
        "\n",
        "# Load GloVe vectors from a text file\n",
        "glove_vectors = {}\n",
        "with open('/content/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in tqdm(f, total=400000):\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_vectors[word] = vector\n",
        "\n",
        "# Create an embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in glove_vectors:\n",
        "        vec = glove_vectors[word]\n",
        "        embedding_matrix[i] = vec\n",
        "    else:\n",
        "        continue\n"
      ],
      "metadata": {
        "id": "SaFBFbOQrzi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vectors\n"
      ],
      "metadata": {
        "id": "qfiudTuDsxzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8.4 Create Dataset generator\n",
        "We need to pass image features for two images as well as the the actual report to our model for training. Thus we create a data generator function to serve our purpose."
      ],
      "metadata": {
        "id": "XVCMXg9BtAT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "def load_image(id_, report):\n",
        "    '''Loads the Image Features with their corresponding Ids'''\n",
        "    img_feature = cheXnet_Features[id_.decode('utf-8')][0]\n",
        "    return img_feature, report\n",
        "\n",
        "def dataset_generator(img_name, caption):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((img_name, caption))\n",
        "\n",
        "    # Use map to load the numpy files in parallel\n",
        "    dataset = dataset.map(lambda item1, item2: tf.numpy_function(load_image, [item1, item2], [tf.float32, tf.string]),\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # Shuffle and batch\n",
        "    dataset = dataset.shuffle(500).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "train_generator = dataset_generator(X_train, y_train)\n",
        "cv_generator = dataset_generator(X_cv, y_cv)\n"
      ],
      "metadata": {
        "id": "jslS_ctlsRyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generator gives provides data in bytes. We create a function that converts them back to strings for manipulation. Also we create a function that takes a batch of data and converts them into new data frame."
      ],
      "metadata": {
        "id": "zLh5wsZbuXur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bytes_to_string(arr):\n",
        "    '''The generator gives provides data in bytes. This function converts them back to strings for manipulation'''\n",
        "    for i in range(len(arr)):\n",
        "        arr[i] = arr[i].decode('utf-8')\n",
        "    return arr\n",
        "\n",
        "def convert(images, reports):\n",
        "    '''This function takes the batch of data and converts them into a new dataset'''\n",
        "    imgs = []\n",
        "    in_reports = []\n",
        "    out_reports = []\n",
        "    for i in range(len(images)):\n",
        "        sequence = [tokenizer.word_index[e] for e in reports[i].split() if e in tokenizer.word_index.keys()]\n",
        "        #  print(sequence)\n",
        "        for j in range(1,len(sequence)):\n",
        "            in_seq = sequence[:j]\n",
        "            out_seq = sequence[j]\n",
        "            out_seq = tf.keras.utils.to_categorical(out_seq, num_classes=vocab_size)\n",
        "\n",
        "            imgs.append(images[i])\n",
        "            #  print(in_seq)\n",
        "            in_reports.append(in_seq)\n",
        "            # print(out_seq)\n",
        "            out_reports.append(out_seq)\n",
        "\n",
        "    return np.array(imgs), np.array(in_reports), np.array(out_reports)\n"
      ],
      "metadata": {
        "id": "DDiWzF43tQ9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.5 Defining our final model\n",
        "Now Since we are equipped with all the necessary utility function and image feature we finally define our sequence to sequence model."
      ],
      "metadata": {
        "id": "qCRk-OQfu6wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = Input(shape=(2048), name='Image_input')\n",
        "dense1 = Dense(256, kernel_initializer=tf.keras.initializers.glorot_uniform(seed = 56), name='dense_encoder')(input1)\n",
        "\n",
        "input2 = Input(shape=(153), name='Text_Input')\n",
        "embedding_layer = Embedding(input_dim = vocab_size, output_dim = 300, input_length=153, mask_zero=True, trainable=False,\n",
        "                weights=[embedding_matrix], name=\"Embedding_layer\")\n",
        "emb = embedding_layer(input2)\n",
        "\n",
        "LSTM1 = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
        "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
        "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
        "            bias_initializer=tf.keras.initializers.zeros(), return_sequences=True, name=\"LSTM1\")(emb)\n",
        "#LSTM1_output = LSTM1(emb)\n",
        "\n",
        "LSTM2 = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
        "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
        "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
        "            bias_initializer=tf.keras.initializers.zeros(), name=\"LSTM2\")\n",
        "LSTM2_output = LSTM2(LSTM1)\n",
        "\n",
        "dropout1 = Dropout(0.5, name='dropout1')(LSTM2_output)\n",
        "\n",
        "dec =  tf.keras.layers.Add()([dense1, dropout1])\n",
        "\n",
        "fc1 = Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.he_normal(seed = 63), name='fc1')\n",
        "fc1_output = fc1(dec)\n",
        "dropout2 = Dropout(0.4, name='dropout2')(fc1_output)\n",
        "output_layer = Dense(vocab_size, activation='softmax', name='Output_layer')\n",
        "output = output_layer(dropout2)\n",
        "\n",
        "encoder_decoder = Model(inputs = [input1, input2], outputs = output)\n",
        "encoder_decoder.summary()"
      ],
      "metadata": {
        "id": "Pi0U4V2zubeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.6 Defining loss function\n",
        "We defined Masked Loss Function for this problem. For eg: If we have a sequence of tokens- [3],[10],[7],[0],[0],[0],[0],[0].We only have 3 words in this sequence, the zeros correspond to the padding which is actually not a part of the report. But the model will think that the zeros are also a part of the sequence and will start learning them. When the model starts to correctly predict the zeros, the loss will decrease because for the model it is learning correctly. But for us the loss should only decrease if the model is predicting the actual words(non-zeros) correctly.\n",
        "\n",
        "Therefore we should mask the zeros in the sequence so that the model don’t give its attention to them and only learns the needed words in the report."
      ],
      "metadata": {
        "id": "LhE33f8UvWdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=False, reduction='auto')\n",
        "\n",
        "def maskedLoss(y_true, y_pred):\n",
        "    #getting mask value\n",
        "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
        "\n",
        "    #calculating the loss\n",
        "    loss_ = loss_function(y_true, y_pred)\n",
        "\n",
        "    #converting mask dtype to loss_ dtype\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "\n",
        "    #applying the mask to loss\n",
        "    loss_ = loss_*mask\n",
        "\n",
        "    #getting mean over all the values\n",
        "    loss_ = tf.reduce_mean(loss_)\n",
        "    return loss_"
      ],
      "metadata": {
        "id": "y3n3YUpSvB1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.7 Model Training\n",
        "Now its time to compile and train our model on the dataset.\n",
        "\n",
        "We are going to use Adam Optimizer for faster convergence. The Adam optimization algorithm is an extension to stochastic gradient descent that has recently seen broader adoption for deep learning applications in computer vision and natural language processing.\n",
        "\n",
        "Adam as combining the advantages of two other extensions of stochastic gradient descent. Specifically:\n",
        "\n",
        "Adaptive Gradient Algorithm (AdaGrad) that maintains a per-parameter learning rate that improves performance on problems with sparse gradients (e.g. natural language and computer vision problems).\n",
        "Root Mean Square Propagation (RMSProp) that also maintains per-parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight (e.g. how quickly it is changing). This means the algorithm does well on online and non-stationary problems (e.g. noisy).\n",
        "Adam realizes the benefits of both AdaGrad and RMSProp.\n",
        "\n",
        "Instead of adapting the parameter learning rates based on the average first moment (the mean) as in RMSProp, Adam also makes use of the average of the second moments of the gradients (the uncentered variance)."
      ],
      "metadata": {
        "id": "V3tVstrBvt1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "encoder_decoder.compile(optimizer, loss = maskedLoss)\n",
        "\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'Tensorboard/logs_m1/fit3/' + current_time + '/train'\n",
        "val_log_dir = 'Tensorboard/logs_m1/fit3/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "val_summary_writer = tf.summary.create_file_writer(val_log_dir)\n",
        "\n",
        "#training for 20 epochs\n",
        "epoch_train_loss = []\n",
        "epoch_val_loss = []\n",
        "\n",
        "for epoch in range(20):\n",
        "    print('EPOCH : ',epoch+1)\n",
        "    start = time.time()\n",
        "    batch_loss_tr = 0\n",
        "    batch_loss_vl = 0\n",
        "\n",
        "    for img, report in train_generator:\n",
        "\n",
        "        r1 = bytes_to_string(report.numpy())\n",
        "        img_input, rep_input, output_word = convert(img.numpy(), r1)\n",
        "        rep_input = pad_sequences(rep_input, maxlen=153, padding='post')\n",
        "        results = encoder_decoder.train_on_batch([img_input, rep_input], output_word)\n",
        "\n",
        "        batch_loss_tr += results\n",
        "\n",
        "    train_loss = batch_loss_tr/(X_train.shape[0]//14)\n",
        " #   print('Saving Tensorboard')\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', train_loss, step = epoch)\n",
        "\n",
        "    for img, report in cv_generator:\n",
        "\n",
        "        r1 = bytes_to_string(report.numpy())\n",
        "        img_input, rep_input, output_word = convert(img.numpy(), r1)\n",
        "        rep_input = pad_sequences(rep_input, maxlen=153, padding='post')\n",
        "        results = encoder_decoder.test_on_batch([img_input, rep_input], output_word)\n",
        "        batch_loss_vl += results\n",
        "\n",
        "    val_loss = batch_loss_vl/(X_cv.shape[0]//14)\n",
        "\n",
        "    with val_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', val_loss, step = epoch)\n",
        "\n",
        "    epoch_train_loss.append(train_loss)\n",
        "\n",
        "    epoch_val_loss.append(val_loss)\n",
        "\n",
        "    print('Training Loss: {},  Val Loss: {}'.format(train_loss, val_loss))\n",
        "    print('Time Taken for this Epoch : {} sec'.format(time.time()-start))\n",
        "    encoder_decoder.save_weights('encoder_decoder_epoch_'+ str(epoch+1) + '.h5')\n",
        "    print('--------------------------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "qgeMmjYavjnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plotting the results\n",
        "plt.plot(range(1, 21), epoch_train_loss, label='Training Loss')\n",
        "plt.plot(range(1, 21), epoch_val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w6-ZR0A3qCWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.8 Interface\n",
        "Now that we have trained our model, it’s time to prepare our model to predict reports. For this purpose we have to make some adjustments in our model. This will save us some time during testing. First we will separate the encoder and decoder part from our model. The features predicted by the encoder will be used as the input to our decoder along with the partial reports."
      ],
      "metadata": {
        "id": "sCYdkecdq1Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder\n",
        "encoder_input = encoder_decoder.input[0]\n",
        "encoder_output = encoder_decoder.get_layer('dense_encoder').output\n",
        "encoder_model = Model(encoder_input, encoder_output)\n",
        "\n",
        "# decoder#\n",
        "text_input = encoder_decoder.input[1]\n",
        "enc_output = Input(shape=(256,), name='Enc_Output')\n",
        "text_output = encoder_decoder.get_layer('LSTM2').output\n",
        "add1 = tf.keras.layers.Add()([text_output, enc_output])\n",
        "fc_1 = fc1(add1)\n",
        "decoder_output = output_layer(fc_1)\n",
        "\n",
        "decoder_model = Model(inputs = [text_input, enc_output], outputs = decoder_output)"
      ],
      "metadata": {
        "id": "22B08PXNq3WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To predict the report form our model given the images, we will use greedy search and beam search algorithm.\n",
        "\n",
        "8.9 Greedy search\n",
        "Greedy is an algorithmic paradigm that builds up a solution piece by piece, always choosing the next piece that offers the most obvious and immediate benefit. So the problems where choosing locally optimal also leads to global solution are best fit for Greedy.\n",
        "\n",
        "A simple approximation is to use a greedy search that selects the most likely word at each step in the output sequence. This approach has the benefit that it is very fast, but the quality of the final output sequences may be far from optimal."
      ],
      "metadata": {
        "id": "sejIvHHIrCZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedysearch(img):\n",
        "    image = cheXnet_Features[img]\n",
        "    input_ = 'startseq'\n",
        "    image_features = encoder_model.predict(image)\n",
        "\n",
        "    result = []\n",
        "    for i in range(153):\n",
        "        input_tok = [tokenizer.word_index[w] for w in input_.split()]\n",
        "        input_padded = pad_sequences([input_tok], 153, padding='post')\n",
        "        predictions = decoder_model.predict([input_padded, image_features])\n",
        "        arg = np.argmax(predictions)\n",
        "        if arg != 7:   # endseq\n",
        "            result.append(tokenizer.index_word[arg])\n",
        "            input_ = input_ + ' ' + tokenizer.index_word[arg]\n",
        "        else:\n",
        "            break\n",
        "    rep = ' '.join(e for e in result)\n",
        "    return rep"
      ],
      "metadata": {
        "id": "VGesgsJPq7PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets define a function that takes index of an image as input and returns both actual and predicted report using greedy search."
      ],
      "metadata": {
        "id": "we8m96XvrL5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_data =pd.read_csv(\"/content/Final_CV_Data.csv\")\n"
      ],
      "metadata": {
        "id": "G1GszTfHsxPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from skimage.transform import resize\n",
        "\n",
        "def load_image(img_name):\n",
        "    image = Image.open(img_name)\n",
        "    X = np.asarray(image.convert(\"RGB\"))\n",
        "    X = np.asarray(X)\n",
        "    X = preprocess_input(X)\n",
        "    X = resize(X, (224, 224, 3))\n",
        "    X = np.expand_dims(X, axis=0)\n",
        "    X = np.asarray(X)\n",
        "    return X\n",
        "\n",
        "def get_result(idx=0):\n",
        "    plt.figure(figsize=(9, 5))\n",
        "\n",
        "    pre_Report = greedysearch(cv_data['Person_id'][idx])  # result after 20 epochs\n",
        "    print('------------------------------------------------------------------------------------------------------')\n",
        "    print(\"Predicted Report : \", pre_Report)\n",
        "    print('------------------------------------------------------------------------------------------------------')\n",
        "    print(\"Actual Report : \", cv_data['Report'][idx])\n",
        "\n",
        "    plt.subplot(121)\n",
        "    img = load_image(cv_data['Image1'][idx])\n",
        "    plt.imshow(img[0])\n",
        "\n",
        "    plt.subplot(122)\n",
        "    img = load_image(cv_data['Image2'][idx])\n",
        "    plt.imshow(img[0])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DV4eJXpcrHnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_result(2)"
      ],
      "metadata": {
        "id": "PTaLkmd7rTPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results(start_idx, end_idx):\n",
        "    for idx in range(start_idx, end_idx):\n",
        "        plt.figure(figsize=(9, 5))\n",
        "\n",
        "        pre_Report = greedysearch(cv_data['Person_id'][idx])  # result after 20 epochs\n",
        "        print('------------------------------------------------------------------------------------------------------')\n",
        "        print(\"Predicted Report : \", pre_Report)\n",
        "        print('------------------------------------------------------------------------------------------------------')\n",
        "        print(\"Actual Report : \", cv_data['Report'][idx])\n",
        "\n",
        "        plt.subplot(121)\n",
        "        img = load_image(cv_data['Image1'][idx])\n",
        "        plt.imshow(img[0])\n",
        "\n",
        "        plt.subplot(122)\n",
        "        img = load_image(cv_data['Image2'][idx])\n",
        "        plt.imshow(img[0])\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Make predictions for images with indices from 0 to 14\n",
        "get_results(0, 15)\n"
      ],
      "metadata": {
        "id": "_zAS2vNA4ITc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_result(2)"
      ],
      "metadata": {
        "id": "IL1PPTbg3I7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights\n",
        "encoder_decoder.save_weights('encoder_decoder_weights.h5')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7snLRC1tuU8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from skimage.transform import resize\n",
        "\n",
        "def load_image(img_name):\n",
        "    image = Image.open(img_name)\n",
        "    X = np.asarray(image.convert(\"RGB\"))\n",
        "    X = np.asarray(X)\n",
        "    X = preprocess_input(X)\n",
        "    X = resize(X, (224, 224, 3))\n",
        "    X = np.expand_dims(X, axis=0)\n",
        "    X = np.asarray(X)\n",
        "    return X\n",
        "\n",
        "def get_result(idx=0):\n",
        "    plt.figure(figsize=(9, 5))\n",
        "\n",
        "    pre_Report = greedysearch(cv_data['Person_id'][idx])  # result after 20 epochs\n",
        "    print('------------------------------------------------------------------------------------------------------')\n",
        "    print(\"Predicted Report : \", pre_Report)\n",
        "    print('------------------------------------------------------------------------------------------------------')\n",
        "    print(\"Actual Report : \", cv_data['Report'][idx])\n",
        "\n",
        "    plt.subplot(121)\n",
        "    img = load_image(cv_data['Image1'][idx])\n",
        "    plt.imshow(img[0])\n",
        "\n",
        "    plt.subplot(122)\n",
        "    img = load_image(cv_data['Image2'][idx])\n",
        "    plt.imshow(img[0])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AmWH_gFZr5Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ze1va--c0Ewt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}