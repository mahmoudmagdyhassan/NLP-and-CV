{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPBttd-K4VPV"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d hazemfahmy/openned-closed-eyes"
      ],
      "metadata": {
        "id": "ureZaxkK4jL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/openned-closed-eyes.zip"
      ],
      "metadata": {
        "id": "gNjcbj555FGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "daDKOtaM5Rw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpath = '/content/TrainingSet/TrainingSet'\n",
        "vpath = '/content/ImprovementSet/ImprovementSet/ImprovementSet'"
      ],
      "metadata": {
        "id": "e8wqYLCi5CpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = keras.preprocessing.image_dataset_from_directory(\n",
        "    vpath,\n",
        "    batch_size =32,\n",
        "    image_size =(227,227),\n",
        "\n",
        "    shuffle = True,\n",
        "    seed =123,\n",
        "    subset ='training',\n",
        "    validation_split=0.01\n",
        "    )\n",
        "validation_data =keras.preprocessing.image_dataset_from_directory(\n",
        "    tpath,\n",
        "    batch_size = 32,\n",
        "    image_size =(227,227),\n",
        "\n",
        "    shuffle = True,\n",
        "    seed =123,\n",
        "    validation_split =0.99,\n",
        "    subset ='validation'\n",
        "\n",
        "    )"
      ],
      "metadata": {
        "id": "LC1SJXvN5b0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(227,227,3),\n",
        "                   pooling='avg',classes=2,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "Gs_8ddPr6Kog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                     optimizer=keras.optimizers.SGD(lr=0.0001),\n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uk1A-tUn6W4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=2\n",
        "history = resnet_model.fit(\n",
        "\n",
        "  training_data,\n",
        "  validation_data=validation_data,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "Ltd-icRM6hjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = '/content/TestSet/TestSet'"
      ],
      "metadata": {
        "id": "pWxGQvkdLXqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata2 = keras.preprocessing.image_dataset_from_directory(\n",
        "    testdata,\n",
        "    batch_size =32,\n",
        "    image_size =(227,227),\n",
        "\n",
        "    shuffle = True,\n",
        "    seed =123,\n",
        "    subset ='training',\n",
        "    validation_split=0.01\n",
        "    )"
      ],
      "metadata": {
        "id": "1qLnoAFyLTDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"evaluating network...\")\n",
        "predIdxs = resnet_model.predict(testdata2)\n",
        "\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "USQhvNOzK2M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.save(\"Drowsiness Detection .model\", save_format=\"h5\")\n",
        "\n",
        "N = 2\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot.png\")\n"
      ],
      "metadata": {
        "id": "SoCJGajfLNOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils.video import VideoStream\n",
        "import numpy as np\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "_8Ce1WWcOR-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prototxtPath = r\"/content/deploy.prototxt\"\n",
        "weightsPath = r\"/content/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "\n",
        "# load the face mask detector model from disk\n",
        "maskNet = load_model(\"/content/Drowsiness Detection .model\")"
      ],
      "metadata": {
        "id": "HHJWqFk_OD2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
        "\n",
        "\t(h, w) = frame.shape[:2]\n",
        "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (227, 227),\n",
        "\t\t(104.0, 177.0, 123.0))\n",
        "\n",
        "\tfaceNet.setInput(blob)\n",
        "\tdetections = faceNet.forward()\n",
        "\tprint(detections.shape)\n",
        "\n",
        "\tfaces = []\n",
        "\tlocs = []\n",
        "\tpreds = []\n",
        "\n",
        "\tfor i in range(0, detections.shape[2]):\n",
        "\t\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\t\tif confidence > 0.5:\n",
        "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t\tface = frame[startY:endY, startX:endX]\n",
        "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\t\tface = cv2.resize(face, (227, 227))\n",
        "\t\t\tface = img_to_array(face)\n",
        "\t\t\tface = preprocess_input(face)\n",
        "\n",
        "\t\t\tfaces.append(face)\n",
        "\t\t\tlocs.append((startX, startY, endX, endY))\n",
        "\n",
        "\tif len(faces) > 0:\n",
        "\t\tfaces = np.array(faces, dtype=\"float32\")\n",
        "\t\tpreds = maskNet.predict(faces, batch_size=32)\n",
        "\n",
        "\treturn (locs, preds)"
      ],
      "metadata": {
        "id": "o6jUWgZfONJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" starting video stream...\")\n",
        "vs = VideoStream(src=0).start()\n",
        "\n",
        "\n",
        "while True:\n",
        "\tframe = vs.read()\n",
        "    frame = imutils.resize(frame, width=400)\n",
        "\n",
        "\t(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
        "\n",
        "\tfor (box, pred) in zip(locs, preds):\n",
        "\t\t(startX, startY, endX, endY) = box\n",
        "\t\t(Closed, Opened) = pred\n",
        "\n",
        "\t\tlabel = \"Closed\" if Closed > Opened else \"Opened\"\n",
        "\t\tcolor = (0, 255, 0) if label == \"Closed\" else (0, 0, 255)\n",
        "\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(Closed, Opened) * 100)\n",
        "\n",
        "\t\tcv2.putText(frame, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "\tcv2.imshow(\"Frame\", frame)\n",
        "\tkey = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "\tif key == ord(\"q\"):\n",
        "\t\tbreak\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "vs.stop()\n"
      ],
      "metadata": {
        "id": "lnJvmsuCO9Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "img = cv2.imread('/content/fd5c4002-93a2-44fd-8d4b-51209e7dcdaa.jpg', cv2.IMREAD_UNCHANGED)\n",
        "frame = imutils.resize(img, width=400)\n",
        "(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
        "for (box, pred) in zip(locs, preds):\n",
        "\t\t(startX, startY, endX, endY) = box\n",
        "\t\t(Closed, Opened) = pred\n",
        "\n",
        "\n",
        "\t\tlabel = \"Closed\" if Closed > Opened else \"Opened\"\n",
        "\t\tcolor = (0, 255, 0) if label == \"Closed\"else (0, 0, 255)\n",
        "\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(Closed, Opened) * 100)\n",
        "\n",
        "\t\tcv2.putText(frame, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "cv2_imshow(frame)"
      ],
      "metadata": {
        "id": "uZYIyTl1QsaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "img = cv2.imread('/content/2014_8_25_10_11_23_418.jpg', cv2.IMREAD_UNCHANGED)\n",
        "frame = imutils.resize(img, width=400)\n",
        "(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
        "for (box, pred) in zip(locs, preds):\n",
        "\t\t(startX, startY, endX, endY) = box\n",
        "\t\t(Closed, Opened) = pred\n",
        "\n",
        "\n",
        "        if Closed > Opened:\n",
        "            engine.say(\"Alert!!!! WAKE UP DUDE\")\n",
        "            engine.runAndWait()\n",
        "        else:\n",
        "            engine.say(\"Alert!!!! good man\")\n",
        "            engine.runAndWait()\n",
        "\n",
        "\n",
        "\t\tlabel = \"Closed\" if Closed > Opened else \"Opened\"\n",
        "\t\tcolor = (0, 255, 0) if label == \"Closed\"else (0, 0, 255)\n",
        "\n",
        "\n",
        "\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(Closed, Opened) * 100)\n",
        "\n",
        "\t\tcv2.putText(frame, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "cv2_imshow(frame)"
      ],
      "metadata": {
        "id": "AUFnBa1ZUozw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}