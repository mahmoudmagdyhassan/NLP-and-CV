{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCwdZC0CEf7x",
        "outputId": "7ab1d0b5-841d-4fa4-fe53-a33db40aba82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import numpy\n",
        "import sys\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/Franknestein.txt\", encoding=\"utf8\") as text_file:\n",
        "    file = text_file.read()\n",
        "print(file)"
      ],
      "metadata": {
        "id": "2fDqUjaEJPbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 100\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 30"
      ],
      "metadata": {
        "id": "zslDi5z2QztI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_words(input):\n",
        "    # lowercase everything to standardize it\n",
        "    input = input.lower()\n",
        "\n",
        "    # instantiate the tokenizer\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(input)\n",
        "\n",
        "    # if the created token isn't in the stop words, make it part of \"filtered\"\n",
        "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "    return \" \".join(filtered)"
      ],
      "metadata": {
        "id": "J6uIRuaAKTH7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenize_words(file)"
      ],
      "metadata": {
        "id": "d2QuwKRjKndV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_chars = len(text)\n",
        "vocab=''.join(sorted(set(text)))\n",
        "n_unique_chars = len(vocab)"
      ],
      "metadata": {
        "id": "fdWYkGrqRH3b"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"n_chars\",n_chars)\n",
        "print(\"_____________\")\n",
        "print(\"vocab\",vocab)\n",
        "print(\"_____________\")\n",
        "print(\"n_unique_chars\",n_unique_chars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibNoJrK7RXD1",
        "outputId": "bab9772a-eea9-474c-b8cf-b72fe778df0b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_chars 269995\n",
            "_____________\n",
            "vocab  0123456789_abcdefghijklmnopqrstuvwxyzæèéêô\n",
            "_____________\n",
            "n_unique_chars 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary that converts characters to integers\n",
        "char2int ={c:i for i ,c in enumerate (vocab)}\n",
        "char2int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKrqL-rZRtaz",
        "outputId": "f6ba0da1-b5f5-4bc6-ab14-5da76b0ad1d4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '0': 1,\n",
              " '1': 2,\n",
              " '2': 3,\n",
              " '3': 4,\n",
              " '4': 5,\n",
              " '5': 6,\n",
              " '6': 7,\n",
              " '7': 8,\n",
              " '8': 9,\n",
              " '9': 10,\n",
              " '_': 11,\n",
              " 'a': 12,\n",
              " 'b': 13,\n",
              " 'c': 14,\n",
              " 'd': 15,\n",
              " 'e': 16,\n",
              " 'f': 17,\n",
              " 'g': 18,\n",
              " 'h': 19,\n",
              " 'i': 20,\n",
              " 'j': 21,\n",
              " 'k': 22,\n",
              " 'l': 23,\n",
              " 'm': 24,\n",
              " 'n': 25,\n",
              " 'o': 26,\n",
              " 'p': 27,\n",
              " 'q': 28,\n",
              " 'r': 29,\n",
              " 's': 30,\n",
              " 't': 31,\n",
              " 'u': 32,\n",
              " 'v': 33,\n",
              " 'w': 34,\n",
              " 'x': 35,\n",
              " 'y': 36,\n",
              " 'z': 37,\n",
              " 'æ': 38,\n",
              " 'è': 39,\n",
              " 'é': 40,\n",
              " 'ê': 41,\n",
              " 'ô': 42}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary that converts integers to characters\n",
        "int2char={i : c for i ,c in enumerate (vocab)}\n",
        "int2char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLkjVDbMRwVo",
        "outputId": "343704c3-7b5b-4398-af2d-08cd2f8abd22"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ' ',\n",
              " 1: '0',\n",
              " 2: '1',\n",
              " 3: '2',\n",
              " 4: '3',\n",
              " 5: '4',\n",
              " 6: '5',\n",
              " 7: '6',\n",
              " 8: '7',\n",
              " 9: '8',\n",
              " 10: '9',\n",
              " 11: '_',\n",
              " 12: 'a',\n",
              " 13: 'b',\n",
              " 14: 'c',\n",
              " 15: 'd',\n",
              " 16: 'e',\n",
              " 17: 'f',\n",
              " 18: 'g',\n",
              " 19: 'h',\n",
              " 20: 'i',\n",
              " 21: 'j',\n",
              " 22: 'k',\n",
              " 23: 'l',\n",
              " 24: 'm',\n",
              " 25: 'n',\n",
              " 26: 'o',\n",
              " 27: 'p',\n",
              " 28: 'q',\n",
              " 29: 'r',\n",
              " 30: 's',\n",
              " 31: 't',\n",
              " 32: 'u',\n",
              " 33: 'v',\n",
              " 34: 'w',\n",
              " 35: 'x',\n",
              " 36: 'y',\n",
              " 37: 'z',\n",
              " 38: 'æ',\n",
              " 39: 'è',\n",
              " 40: 'é',\n",
              " 41: 'ê',\n",
              " 42: 'ô'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert all text into integers\n",
        "import numpy as np\n",
        "encoded_text=np.array([char2int[c]for c in text])\n",
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tP62OaoR2Sb",
        "outputId": "1d3dc3da-6193-4c56-ecd5-a3d427e7bd03"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([27, 29, 26, ..., 26, 22, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct tf.data.Dataset object\n",
        "import tensorflow as tf\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "char_dataset"
      ],
      "metadata": {
        "id": "koLXjGXmSHeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 100\n",
        "#تقطيع النص كله الي بيانات مقطعة\n",
        "# build sequences by batching\n",
        "sequences = char_dataset.batch(2*sequence_length + 1, drop_remainder=True)\n",
        "sequences"
      ],
      "metadata": {
        "id": "Dij8VmcJSegx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sequence in sequences.take(3):\n",
        "  print(''.join([int2char[i] for i in sequence.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcnhtlI9SluR",
        "outputId": "28f6b8b2-fbd2-478a-af35-b95df278602c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "project gutenberg frankenstein mary wollstonecraft godwin shelley ebook use anyone anywhere cost almost restrictions whatsoever may copy give away use terms project gutenberg license included ebook onl\n",
            "ine www gutenberg net title frankenstein modern prometheus author mary wollstonecraft godwin shelley release date june 17 2008 ebook 84 last updated january 13 2018 language english character set encod\n",
            "ing utf 8 start project gutenberg ebook frankenstein produced judith boss christy phillips lynn hanninen david meltzer html version al haines corrections menno de leeuw frankenstein modern prometheus m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sample(sample):\n",
        "      ds = tf.data.Dataset.from_tensors((sample[:sequence_length], sample[sequence_length]))\n",
        "      for i in range(1, (len(sample)-1) // 2):\n",
        "        input_ = sample[i: i+sequence_length]\n",
        "        target = sample[i+sequence_length]\n",
        "        # extend the dataset with these samples by concatenate() method\n",
        "        other_ds = tf.data.Dataset.from_tensors((input_, target))\n",
        "        ds = ds.concatenate(other_ds)\n",
        "      return ds\n",
        "# prepare inputs and targets\n",
        "dataset = sequences.flat_map(split_sample)"
      ],
      "metadata": {
        "id": "WP9qJ7qVSW3i"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_samples(input_, target):\n",
        "    # onehot encode the inputs and the targets\n",
        "    return tf.one_hot(input_, n_unique_chars), tf.one_hot(target, n_unique_chars)\n",
        "\n",
        "\n",
        "dataset = dataset.map(one_hot_samples)"
      ],
      "metadata": {
        "id": "emdF7hjEStYG"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print first 2 samples\n",
        "for element in dataset.take(2):\n",
        "    print(\"Input:\", ''.join([int2char[np.argmax(char_vector)] for char_vector in element[0].numpy()]))\n",
        "    print(\"Target:\", int2char[np.argmax(element[1].numpy())])\n",
        "    print(\"Input shape:\", element[0].shape)\n",
        "    print(\"Target shape:\", element[1].shape)\n",
        "    print(\"=\"*50, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBq9LnC_SvRV",
        "outputId": "f6593188-394a-4591-c984-a1a1fc2d7c8f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: project gutenberg frankenstein mary wollstonecraft godwin shelley ebook use anyone anywhere cost alm\n",
            "Target: o\n",
            "Input shape: (100, 43)\n",
            "Target shape: (43,)\n",
            "================================================== \n",
            "\n",
            "Input: roject gutenberg frankenstein mary wollstonecraft godwin shelley ebook use anyone anywhere cost almo\n",
            "Target: s\n",
            "Input shape: (100, 43)\n",
            "Target shape: (43,)\n",
            "================================================== \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#عمل خلط للبيانات و تقسيمها الي باشتات\n",
        "# repeat, shuffle and batch the dataset\n",
        "ds = dataset.repeat().shuffle(1024).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "QoO4Kg5hS9t2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#بناء الموديل\n",
        "model = Sequential([\n",
        "    LSTM(256, input_shape=(sequence_length, n_unique_chars), return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(256),\n",
        "    Dense(n_unique_chars, activation=\"softmax\"),\n",
        "])"
      ],
      "metadata": {
        "id": "I3ILJA7uTY3W"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.fit(ds, steps_per_epoch=(len(encoded_text) - sequence_length) // BATCH_SIZE, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DrjH2O6TeWM",
        "outputId": "aa8a7bed-940f-4f31-90d3-b40dc9a85cf0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "2108/2108 [==============================] - 3206s 2s/step - loss: 2.1863\n",
            "Epoch 2/4\n",
            "2108/2108 [==============================] - 3133s 1s/step - loss: 1.6795\n",
            "Epoch 3/4\n",
            "2108/2108 [==============================] - 3070s 1s/step - loss: 1.4670\n",
            "Epoch 4/4\n",
            "2108/2108 [==============================] - 3081s 1s/step - loss: 1.3479\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a55a0ea9b70>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"git+https://github.com/tqdm/tqdm.git@devel#egg=tqdm\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCVqz9iHTpi3",
        "outputId": "5b447b98-717e-42a5-9a51-2e2c449eb50f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tqdm\n",
            "  Cloning https://github.com/tqdm/tqdm.git (to revision devel) to /tmp/pip-install-yvk1y4bp/tqdm_8cd81d5a41174512afeee50a24aea2f1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tqdm/tqdm.git /tmp/pip-install-yvk1y4bp/tqdm_8cd81d5a41174512afeee50a24aea2f1\n",
            "  Running command git checkout -b devel --track origin/devel\n",
            "  Switched to a new branch 'devel'\n",
            "  Branch 'devel' set up to track remote branch 'devel' from 'origin'.\n",
            "  Resolved https://github.com/tqdm/tqdm.git to commit 6ce50bedb3c525f762258fb0701aacae15515f4d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tqdm\n",
            "  Building wheel for tqdm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tqdm: filename=tqdm-4.66.1.dev2+g6ce50be-py3-none-any.whl size=78482 sha256=f4cdf3b3ef820d0928f783aee2321d236f4ba5cbd7bbd1b85da4f74f1f94653b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dxskfigf/wheels/58/37/2e/a68b55bdff1a302c7a4a688e0237765287e22abddc0f8382b8\n",
            "Successfully built tqdm\n",
            "Installing collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "Successfully installed tqdm-4.66.1.dev2+g6ce50be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "seed = \"chapter xiii\"\n",
        "vocab_size = len(char2int)\n",
        "s = seed\n",
        "n_chars = 200\n",
        "# generate 400 characters\n",
        "generated = \"\"\n",
        "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
        "    # make the input sequence\n",
        "    X = np.zeros((1, sequence_length, vocab_size))\n",
        "    for t, char in enumerate(seed):\n",
        "        X[0, (sequence_length - len(seed)) + t, char2int[char]] = 1\n",
        "    # predict the next character\n",
        "    predicted = model.predict(X, verbose=0)[0]\n",
        "    # converting the vector to an integer\n",
        "    next_index = np.argmax(predicted)\n",
        "    # converting the integer to a character\n",
        "    next_char = int2char[next_index]\n",
        "    # add the character to results\n",
        "    generated += next_char\n",
        "    # shift seed and the predicted character\n",
        "    seed = seed[1:] + next_char\n",
        "\n",
        "print(\"Seed:\", s)\n",
        "print(\"Generated text:\")\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqPdQ518TsQS",
        "outputId": "7e23da0e-f553-4a44-cd2d-c8e83b0405b8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating text: 100%|██████████| 200/200 [00:17<00:00, 11.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: chapter xiii\n",
            "Generated text:\n",
            "n state assure seas compliance endeavoured commance enterprise misery courage accomplish enterprise misery courage accomplish enterprise misery courage accomplish enterprise misery courage accomplish \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.integrations import NeptuneCallback\n",
        "\n",
        "# Create Neptune callback\n",
        "neptune_callback = NeptuneCallback(\n",
        "    name=\"DistilBERT\",\n",
        "    description=\"DistilBERT fine-tuned on GLUE/MRPC\",\n",
        "    tags=[\"args-callback\", \"fine-tune\", \"MRPC\"],  # tags help you manage runs\n",
        "    base_namespace=\"custom_name\",  # the default is \"finetuning\"\n",
        "    log_checkpoints=\"best\",  # other options are \"last\", \"same\", and None\n",
        "    capture_hardware_metrics=False,  # additional kwargs for a Neptune run\n",
        ")\n",
        "\n",
        "# Create training arguments\n",
        "training_args = TrainingArguments(\n",
        "    \"quick-training-distilbert-mrpc\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=20,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Pass Neptune callback to Trainer\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    callbacks=[neptune_callback],\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "J0pzE8KRTuub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(processed_inputs)"
      ],
      "metadata": {
        "id": "wNeTZltZLT7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_inputs[:2000]"
      ],
      "metadata": {
        "id": "YmSa_QPsLaMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(processed_inputs)))"
      ],
      "metadata": {
        "id": "shFcMT_MLj8l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IL2SAKBLo2V",
        "outputId": "8af259ab-cadc-40ba-d2ac-4bbf20e714b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzjd-MeoLrsG",
        "outputId": "234c7fdd-181a-4a4d-db58-243858f7a204"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '_', 'a', 'b', 'c']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num = dict((c, i) for i, c in enumerate(chars))\n",
        "char_to_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzThr7N6LvgF",
        "outputId": "84a13bba-0727-405c-8f8f-3996f3530c4b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '0': 1,\n",
              " '1': 2,\n",
              " '2': 3,\n",
              " '3': 4,\n",
              " '4': 5,\n",
              " '5': 6,\n",
              " '6': 7,\n",
              " '7': 8,\n",
              " '8': 9,\n",
              " '9': 10,\n",
              " '_': 11,\n",
              " 'a': 12,\n",
              " 'b': 13,\n",
              " 'c': 14,\n",
              " 'd': 15,\n",
              " 'e': 16,\n",
              " 'f': 17,\n",
              " 'g': 18,\n",
              " 'h': 19,\n",
              " 'i': 20,\n",
              " 'j': 21,\n",
              " 'k': 22,\n",
              " 'l': 23,\n",
              " 'm': 24,\n",
              " 'n': 25,\n",
              " 'o': 26,\n",
              " 'p': 27,\n",
              " 'q': 28,\n",
              " 'r': 29,\n",
              " 's': 30,\n",
              " 't': 31,\n",
              " 'u': 32,\n",
              " 'v': 33,\n",
              " 'w': 34,\n",
              " 'x': 35,\n",
              " 'y': 36,\n",
              " 'z': 37,\n",
              " 'æ': 38,\n",
              " 'è': 39,\n",
              " 'é': 40,\n",
              " 'ê': 41,\n",
              " 'ô': 42}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print (\"Total number of characters:\", input_len)\n",
        "print (\"Total vocab:\", vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynbie7MWL0sy",
        "outputId": "db42c700-06f0-456d-e799-6072f5d8ba05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 269995\n",
            "Total vocab: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "# loop through inputs, start at the beginning and go until we hit\n",
        "# the final character we can create a sequence out of\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "    # Define input and output sequences\n",
        "    # Input is the current character plus desired sequence length\n",
        "    in_seq = processed_inputs[i:i + seq_length]\n",
        "\n",
        "    # Out sequence is the initial character plus total sequence length\n",
        "    out_seq = processed_inputs[i + seq_length]\n",
        "\n",
        "    # We now convert list of characters to integers based on\n",
        "    # previously and add the values to our lists\n",
        "    x_data.append([char_to_num[char] for char in in_seq])\n",
        "    y_data.append(char_to_num[out_seq])"
      ],
      "metadata": {
        "id": "S1Tsn8i2L5dF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_patterns = len(x_data)\n",
        "print (\"Total Patterns:\", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzj9YHU7Mdly",
        "outputId": "cf54009a-5893-4646-e596-3c8087a5d061"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: 269895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQOMf9qbMjju",
        "outputId": "bf426f26-7731-4f0d-86a0-181d5aef9786"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(269895, 100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X/float(vocab_len)"
      ],
      "metadata": {
        "id": "dhtOVKtDM9DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras.utils\n"
      ],
      "metadata": {
        "id": "_BEt4dhiNUOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n"
      ],
      "metadata": {
        "id": "f443VdHWNii9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np_utils.to_categorical(y_data)"
      ],
      "metadata": {
        "id": "1-hvrfptNI6z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}